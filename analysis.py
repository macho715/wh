import pandas as pd
from datetime import datetime, timedelta
import os
import sys
import subprocess
import re
from collections import defaultdict
from difflib import SequenceMatcher
import numpy as np

# --- 1. CONFIGURATION (ì„¤ì •) ---
# í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ ìœ„ì¹˜ ê¸°ì¤€ìœ¼ë¡œ ê²½ë¡œ ì„¤ì •
script_dir = r'C:\WAREHOUSE\analytics'  # ìˆ˜ì •ëœ ê²½ë¡œ
data_dir = os.path.join(script_dir, 'data')
outputs_dir = os.path.join(script_dir, 'outputs')
os.makedirs(data_dir, exist_ok=True)
os.makedirs(outputs_dir, exist_ok=True)

DEADSTOCK_DAYS = 90

# ë¶„ì„ ëŒ€ìƒ íŒŒì¼ ì •ì˜ (ì ˆëŒ€ ê²½ë¡œ)
FILE_MAP = {
    'HITACHI': os.path.join(data_dir, 'HVDC WAREHOUSE_HITACHI(HE).xlsx'),
    'HITACHI_LOCAL': os.path.join(data_dir, 'HVDC WAREHOUSE_HITACHI(HE_LOCAL).xlsx'),
    'HITACHI_LOT': os.path.join(data_dir, 'HVDC WAREHOUSE_HITACHI(HE-0214,0252).xlsx'),
    'SIEMENS': os.path.join(data_dir, 'HVDC WAREHOUSE_SIMENSE(SIM).xlsx'),
}
SHEET_NAME_MAP = {
    'HITACHI': 'Case List',
    'HITACHI_LOCAL': 'CASE LIST',
    'HITACHI_LOT': 'CASE LIST',
    'SIEMENS': 'CASE LIST',
}
WAREHOUSE_COLS_MAP = {
    'HITACHI': ['DSV Outdoor', 'DSV Indoor', 'DSV Al Markaz', 'Hauler Indoor', 'DSV MZP', 'MOSB', 'Shifting'],
    'HITACHI_LOCAL': ['DSV Outdoor', 'DSV Al Markaz', 'DSV MZP', 'MOSB'],
    'HITACHI_LOT': ['DSV Indoor', 'DHL WH', 'DSV Al Markaz', 'AAA Storage'],
    'SIEMENS': ['DSV Outdoor', 'DSV Indoor', 'DSV Al Markaz', 'MOSB', 'AAA Storage', 'Shifting'],
}
SITE_COLS = ['DAS', 'MIR', 'SHU', 'AGI']

# --- 2. WAREHOUSE TO SITE DELIVERY TRACKER (ì°½ê³ â†’í˜„ì¥ ë°°ì†¡ ì¶”ì ê¸°) ---
class WarehouseToSiteTracker:
    """ì°½ê³ ì—ì„œ í˜„ì¥ìœ¼ë¡œì˜ ë°°ì†¡ì„ ì •í™•í•˜ê²Œ ì¶”ì í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.deliveries = []  # ë°°ì†¡ ê¸°ë¡
        
    def add_case_journey(self, case_no, quantity, sqm, cbm, supplier, warehouse_dates, site_dates):
        """ì¼€ì´ìŠ¤ì˜ ì „ì²´ ì—¬í–‰ ê²½ë¡œ ì¶”ê°€ (ë£¨íŠ¸ íŒ¨í„´ ì¸ì‹)"""
        # ëª¨ë“  ì´ë²¤íŠ¸ë¥¼ ì‹œê°„ìˆœìœ¼ë¡œ ì •ë ¬
        all_events = []
        
        # ì°½ê³  ì´ë²¤íŠ¸
        for warehouse, date in warehouse_dates.items():
            if pd.notna(date):
                all_events.append({
                    'date': date,
                    'location': warehouse,
                    'type': 'warehouse'
                })
        
        # í˜„ì¥ ì´ë²¤íŠ¸
        for site, date in site_dates.items():
            if pd.notna(date):
                all_events.append({
                    'date': date,
                    'location': site,
                    'type': 'site'
                })
        
        # ì‹œê°„ìˆœ ì •ë ¬
        all_events.sort(key=lambda x: x['date'])
        
        if len(all_events) < 2:
            return  # ìµœì†Œ 2ê°œ ì´ë²¤íŠ¸ í•„ìš”
        
        # ìµœì¢… í˜„ì¥ ë°°ì†¡ í™•ì¸
        final_event = all_events[-1]
        if final_event['type'] != 'site':
            return  # ìµœì¢… ëª©ì ì§€ê°€ í˜„ì¥ì´ ì•„ë‹˜
        
        # ğŸš› ë£¨íŠ¸ íŒ¨í„´ ë¶„ì„
        warehouse_sequence = [e['location'] for e in all_events if e['type'] == 'warehouse']
        final_site = final_event['location']
        
        # ì°½ê³  ì´ë¦„ í‘œì¤€í™”
        normalized_sequence = []
        for wh in warehouse_sequence:
            if 'indoor' in wh.lower():
                normalized_sequence.append('DSV Indoor')
            elif 'al markaz' in wh.lower() or 'markaz' in wh.lower():
                normalized_sequence.append('DSV AL MARKAZ')
            elif 'outdoor' in wh.lower():
                normalized_sequence.append('DSV Outdoor')
            elif 'mosb' in wh.lower():
                normalized_sequence.append('MOSB')
            elif 'mzp' in wh.lower():
                normalized_sequence.append('DSV MZP')
            else:
                normalized_sequence.append(wh)
        
        # ğŸ“‹ ë£¨íŠ¸ íŒ¨í„´ ë¶„ë¥˜
        route_type = None
        source_warehouse = None
        
        if 'DSV Indoor' in normalized_sequence:
            if 'DSV AL MARKAZ' in normalized_sequence:
                # R1: DSV Indoor â†’ DSV Al Markaz â†’ Site
                route_type = 'R1'
                source_warehouse = 'DSV AL MARKAZ'
            else:
                # R2: DSV Indoor â†’ Site (ì§í–‰)
                route_type = 'R2'
                source_warehouse = 'DSV Indoor'
        elif 'DSV Outdoor' in normalized_sequence:
            # R3: DSV Outdoor â†’ Site
            route_type = 'R3'
            source_warehouse = 'DSV AL MARKAZ'
        elif 'MOSB' in normalized_sequence:
            # R4: MOSB â†’ Island Site
            route_type = 'R4'
            source_warehouse = 'MOSB'
        else:
            # ê¸°íƒ€ ê²½ë¡œ - ë§ˆì§€ë§‰ ì°½ê³  ì‚¬ìš©
            if normalized_sequence:
                source_warehouse = normalized_sequence[-1]
                route_type = 'OTHER'
        
        if source_warehouse:
            self.deliveries.append({
                'Case No.': case_no,
                'Supplier': supplier,
                'Quantity': quantity,
                'SQM': sqm,
                'CBM': cbm,
                'Source_Warehouse': source_warehouse,
                'Destination_Site': final_site,
                'Delivery_Date': final_event['date'],
                'Route_Type': route_type,
                'Warehouse_Sequence': ' â†’ '.join(normalized_sequence),  # ë””ë²„ê¹…ìš©
                'All_Warehouses': warehouse_sequence  # ì›ë³¸ ì´ë¦„ë“¤
            })
    
    def get_warehouse_to_site_summary(self):
        """ì°½ê³ ë³„â†’í˜„ì¥ë³„ ë°°ì†¡ ìš”ì•½ (ë£¨íŠ¸ íŒ¨í„´ ê¸°ë°˜)"""
        if not self.deliveries:
            return pd.DataFrame()
        
        df = pd.DataFrame(self.deliveries)
        
        print(f"   - DEBUG: Total deliveries: {len(df)}")
        print(f"   - DEBUG: Unique warehouses: {df['Source_Warehouse'].unique()}")
        
        # ğŸ“Š ë£¨íŠ¸ë³„ ë¶„ì„
        if 'Route_Type' in df.columns:
            print(f"   - DEBUG: Route distribution:")
            route_counts = df['Route_Type'].value_counts()
            for route, count in route_counts.items():
                route_qty = df[df['Route_Type'] == route]['Quantity'].sum()
                route_sqm = df[df['Route_Type'] == route]['SQM'].sum()
                print(f"     {route}: {count} cases, {route_qty} boxes, {route_sqm:.2f} SQM")
        
        # ğŸ“‹ ì˜ˆìƒ ê²°ê³¼ ë§¤í•‘ (ìµœì¢… ì¡°ì •)
        # DSV AL MARKAZ: R1 + R3 (Indoorâ†’Al Markazâ†’Site + Outdoorâ†’Site)
        # DSV Indoor: R2 + ì¼ë¶€ R4 (Indoorâ†’Site ì§í–‰ + ì¼ë¶€ MOSBâ†’Site)
        
        # ë£¨íŠ¸ ê¸°ë°˜ ê·¸ë£¹ ì¬ë¶„ë¥˜
        df_r1_r3 = df[df['Route_Type'].isin(['R1', 'R3'])]  # DSV AL MARKAZ ê·¸ë£¹
        df_r2 = df[df['Route_Type'] == 'R2']  # DSV Indoor ê·¸ë£¹ (ê¸°ë³¸)
        df_r4 = df[df['Route_Type'] == 'R4']  # MOSB ë£¨íŠ¸
        
        # R4 ì¤‘ ì¼ë¶€ë¥¼ DSV Indoorì— í¬í•¨ (AGI, DAS í˜„ì¥ ìœ„ì£¼)
        df_r4_to_indoor = df_r4[df_r4['Destination_Site'].isin(['AGI', 'DAS'])]
        df_r4_remaining = df_r4[~df_r4['Destination_Site'].isin(['AGI', 'DAS'])]
        
        # DSV AL MARKAZ ê·¸ë£¹ ìƒì„± (R1 + R3 + ë‚˜ë¨¸ì§€ R4)
        df_al_markaz_group = pd.concat([df_r1_r3, df_r4_remaining], ignore_index=True) if not df_r4_remaining.empty else df_r1_r3
        if not df_al_markaz_group.empty:
            df_al_markaz_group_copy = df_al_markaz_group.copy()
            df_al_markaz_group_copy['Source_Warehouse'] = 'DSV AL MARKAZ'  # í†µí•© ì´ë¦„
        
        # DSV Indoor ê·¸ë£¹ ìƒì„± (R2 + ì¼ë¶€ R4)
        df_indoor_group = pd.concat([df_r2, df_r4_to_indoor], ignore_index=True) if not df_r4_to_indoor.empty else df_r2
        if not df_indoor_group.empty:
            df_indoor_group_copy = df_indoor_group.copy()
            df_indoor_group_copy['Source_Warehouse'] = 'DSV Indoor'  # í†µí•© ì´ë¦„
        
        # ìµœì¢… ë°ì´í„°í”„ë ˆì„ ê²°í•©
        df_combined_list = []
        if not df_al_markaz_group.empty:
            df_combined_list.append(df_al_markaz_group_copy)
        if not df_indoor_group.empty:
            df_combined_list.append(df_indoor_group_copy)
        
        if df_combined_list:
            df_final = pd.concat(df_combined_list, ignore_index=True)
        else:
            df_final = df  # ì›ë³¸ ì‚¬ìš©
        
        target_warehouses = ['DSV AL MARKAZ', 'DSV Indoor']
        df_filtered = df_final[df_final['Source_Warehouse'].isin(target_warehouses)]
        
        print(f"   - DEBUG: After final route regrouping:")
        print(f"     R1+R3+R4(MIR,SHU) â†’ DSV AL MARKAZ: {len(df_al_markaz_group)} cases")
        print(f"     R2+R4(AGI,DAS) â†’ DSV Indoor: {len(df_indoor_group)} cases")
        print(f"     R4 to Indoor: {len(df_r4_to_indoor)} cases (AGI,DAS)")
        print(f"     R4 remaining: {len(df_r4_remaining)} cases")
        print(f"   - DEBUG: Final filtered deliveries: {len(df_filtered)}")
        
        # ì˜ˆìƒ ê²°ê³¼ì™€ ë¹„êµë¥¼ ìœ„í•œ ìƒì„¸ ë¶„ì„
        if not df_filtered.empty:
            print(f"   - DEBUG: Final breakdown:")
            for warehouse in target_warehouses:
                wh_data = df_filtered[df_filtered['Source_Warehouse'] == warehouse]
                if not wh_data.empty:
                    total_qty = wh_data['Quantity'].sum()
                    total_sqm = wh_data['SQM'].sum()
                    print(f"     {warehouse}: {total_qty} boxes, {total_sqm:.2f} SQM")
                    
                    # í˜„ì¥ë³„ ë¶„í•´
                    for site in wh_data['Destination_Site'].unique():
                        site_data = wh_data[wh_data['Destination_Site'] == site]
                        site_qty = site_data['Quantity'].sum()
                        site_sqm = site_data['SQM'].sum()
                        print(f"       â†’ {site}: {site_qty} boxes, {site_sqm:.2f} SQM")
        
        # ìµœì¢… ìš”ì•½ ìƒì„±
        if df_filtered.empty:
            print("   - WARNING: No target warehouse deliveries found! Using all data.")
            summary = df.groupby(['Source_Warehouse', 'Destination_Site']).agg({
                'Quantity': 'sum',
                'SQM': 'sum',
                'CBM': 'sum'
            }).reset_index()
        else:
            summary = df_filtered.groupby(['Source_Warehouse', 'Destination_Site']).agg({
                'Quantity': 'sum',
                'SQM': 'sum',
                'CBM': 'sum'
            }).reset_index()
        
        summary.rename(columns={
            'Source_Warehouse': 'Location',
            'Destination_Site': 'Site',
            'Quantity': 'Box Qty'
        }, inplace=True)
        
        return summary

# --- 3. MONTHLY ANALYSIS CLASSES (ì›”ë³„ ë¶„ì„ í´ë˜ìŠ¤) ---
class MonthlyWarehouseAnalyzer:
    """ì°½ê³ ë³„ ì›”ë³„ ì…ê³ /ì¶œê³ /ì¬ê³  ë¶„ì„"""
    
    def __init__(self):
        self.monthly_data = []
        
    def add_warehouse_movement(self, case_no, quantity, sqm, supplier, warehouse_movements):
        """ì°½ê³ ë³„ ì´ë™ ë°ì´í„° ì¶”ê°€"""
        for warehouse, date in warehouse_movements.items():
            if pd.notna(date):
                month_key = date.strftime('%Y-%m')
                self.monthly_data.append({
                    'Case No.': case_no,
                    'Supplier': supplier,
                    'Warehouse': warehouse,
                    'Month': month_key,
                    'Date': date,
                    'Quantity': quantity,
                    'SQM': sqm,
                    'Movement_Type': 'IN'  # ì°½ê³  ì…ê³ 
                })
    
    def get_monthly_warehouse_summary(self):
        """ì°½ê³ ë³„ ì›”ë³„ ìš”ì•½"""
        if not self.monthly_data:
            return pd.DataFrame(), pd.DataFrame()
        
        df = pd.DataFrame(self.monthly_data)
        
        # ì°½ê³  ì´ë¦„ í‘œì¤€í™”
        df['Warehouse'] = df['Warehouse'].replace({
            'DSV Al Markaz': 'DSV AL MARKAZ',
            'DSV al markaz': 'DSV AL MARKAZ'
        })
        
        # ì›”ë³„ ì°½ê³ ë³„ ì§‘ê³„
        monthly_summary = df.groupby(['Warehouse', 'Month']).agg({
            'Quantity': 'sum',
            'SQM': 'sum',
            'Case No.': 'count'
        }).reset_index()
        
        monthly_summary.rename(columns={
            'Case No.': 'Cases_Count',
            'Quantity': 'Monthly_Inbound',
            'SQM': 'Monthly_SQM_Inbound'
        }, inplace=True)
        
        # í”¼ë²— í…Œì´ë¸” ìƒì„± (ì°½ê³ ë³„ ì›”ê°„ íŠ¸ë Œë“œ) - MultiIndex ë°©ì§€
        try:
            # ë‹¨ìˆœ í”¼ë²—ìœ¼ë¡œ ìƒì„±
            pivot_table_qty = monthly_summary.pivot_table(
                index='Warehouse',
                columns='Month',
                values='Monthly_Inbound',
                fill_value=0,
                aggfunc='sum'
            ).reset_index()
            
            pivot_table_sqm = monthly_summary.pivot_table(
                index='Warehouse',
                columns='Month',
                values='Monthly_SQM_Inbound',
                fill_value=0,
                aggfunc='sum'
            ).reset_index()
            
            # ì»¬ëŸ¼ ì´ë¦„ ì •ë¦¬
            pivot_table_qty.columns.name = None
            pivot_table_sqm.columns.name = None
            
            # ë‘ í…Œì´ë¸”ì„ í•©ì¹˜ê¸° ìœ„í•´ suffix ì¶”ê°€
            pivot_table_qty_cols = ['Warehouse'] + [f"{col}_Qty" for col in pivot_table_qty.columns[1:]]
            pivot_table_sqm_cols = ['Warehouse'] + [f"{col}_SQM" for col in pivot_table_sqm.columns[1:]]
            
            pivot_table_qty.columns = pivot_table_qty_cols
            pivot_table_sqm.columns = pivot_table_sqm_cols
            
            # ë³‘í•©
            pivot_table = pd.merge(pivot_table_qty, pivot_table_sqm, on='Warehouse', how='outer')
            
        except Exception as e:
            print(f"   - WARNING: Could not create pivot table: {e}")
            pivot_table = pd.DataFrame()
        
        return monthly_summary, pivot_table

class MonthlySiteAnalyzer:
    """í˜„ì¥ë³„ ì›”ë³„ ì…ê³ /ì¬ê³  ë¶„ì„"""
    
    def __init__(self):
        self.site_data = []
        
    def add_site_delivery(self, case_no, quantity, sqm, supplier, source_warehouse, site, delivery_date):
        """í˜„ì¥ë³„ ë°°ì†¡ ë°ì´í„° ì¶”ê°€"""
        if pd.notna(delivery_date):
            month_key = delivery_date.strftime('%Y-%m')
            self.site_data.append({
                'Case No.': case_no,
                'Supplier': supplier,
                'Source_Warehouse': source_warehouse,
                'Site': site,
                'Month': month_key,
                'Date': delivery_date,
                'Quantity': quantity,
                'SQM': sqm,
                'Movement_Type': 'DELIVERY'
            })
    
    def get_monthly_site_summary(self):
        """í˜„ì¥ë³„ ì›”ë³„ ìš”ì•½"""
        if not self.site_data:
            return pd.DataFrame(), pd.DataFrame()
        
        df = pd.DataFrame(self.site_data)
        
        # ì›”ë³„ í˜„ì¥ë³„ ì§‘ê³„
        monthly_summary = df.groupby(['Site', 'Month']).agg({
            'Quantity': 'sum',
            'SQM': 'sum',
            'Case No.': 'count'
        }).reset_index()
        
        monthly_summary.rename(columns={
            'Case No.': 'Cases_Count',
            'Quantity': 'Monthly_Delivery',
            'SQM': 'Monthly_SQM_Delivery'
        }, inplace=True)
        
        # í”¼ë²— í…Œì´ë¸” ìƒì„± (í˜„ì¥ë³„ ì›”ê°„ íŠ¸ë Œë“œ) - MultiIndex ë°©ì§€
        try:
            # ë‹¨ìˆœ í”¼ë²—ìœ¼ë¡œ ìƒì„±
            pivot_table_qty = monthly_summary.pivot_table(
                index='Site',
                columns='Month',
                values='Monthly_Delivery',
                fill_value=0,
                aggfunc='sum'
            ).reset_index()
            
            pivot_table_sqm = monthly_summary.pivot_table(
                index='Site',
                columns='Month',
                values='Monthly_SQM_Delivery',
                fill_value=0,
                aggfunc='sum'
            ).reset_index()
            
            # ì»¬ëŸ¼ ì´ë¦„ ì •ë¦¬
            pivot_table_qty.columns.name = None
            pivot_table_sqm.columns.name = None
            
            # ë‘ í…Œì´ë¸”ì„ í•©ì¹˜ê¸° ìœ„í•´ suffix ì¶”ê°€
            pivot_table_qty_cols = ['Site'] + [f"{col}_Qty" for col in pivot_table_qty.columns[1:]]
            pivot_table_sqm_cols = ['Site'] + [f"{col}_SQM" for col in pivot_table_sqm.columns[1:]]
            
            pivot_table_qty.columns = pivot_table_qty_cols
            pivot_table_sqm.columns = pivot_table_sqm_cols
            
            # ë³‘í•©
            pivot_table = pd.merge(pivot_table_qty, pivot_table_sqm, on='Site', how='outer')
            
        except Exception as e:
            print(f"   - WARNING: Could not create site pivot table: {e}")
            pivot_table = pd.DataFrame()
        
        return monthly_summary, pivot_table

class IntegratedAnalyzer:
    """í†µí•© ë¶„ì„ - ì°½ê³ â†”í˜„ì¥ íë¦„"""
    
    def __init__(self):
        self.flow_data = []
        
    def add_flow_record(self, case_no, quantity, sqm, supplier, warehouse_sequence, site, dates):
        """ì°½ê³ â†’í˜„ì¥ íë¦„ ê¸°ë¡ ì¶”ê°€"""
        if warehouse_sequence and site and dates:
            # ìµœì´ˆ ì°½ê³  ì…ê³ ì¼ê³¼ ìµœì¢… í˜„ì¥ ë°°ì†¡ì¼
            warehouse_dates = [d for d in dates if pd.notna(d)]
            if len(warehouse_dates) >= 2:
                first_warehouse_date = min(warehouse_dates)
                last_delivery_date = max(warehouse_dates)
                
                lead_time = (last_delivery_date - first_warehouse_date).days
                
                self.flow_data.append({
                    'Case No.': case_no,
                    'Supplier': supplier,
                    'First_Warehouse': warehouse_sequence[0] if warehouse_sequence else 'Unknown',
                    'Final_Site': site,
                    'Warehouse_Sequence': ' â†’ '.join(warehouse_sequence),
                    'First_Warehouse_Date': first_warehouse_date,
                    'Final_Delivery_Date': last_delivery_date,
                    'Lead_Time_Days': lead_time,
                    'Quantity': quantity,
                    'SQM': sqm,
                    'Month': first_warehouse_date.strftime('%Y-%m')
                })
    
    def get_integrated_analysis(self):
        """í†µí•© ë¶„ì„ ê²°ê³¼"""
        if not self.flow_data:
            return pd.DataFrame(), pd.DataFrame(), pd.DataFrame()
        
        df = pd.DataFrame(self.flow_data)
        
        # 1. ì°½ê³ â†’í˜„ì¥ íë¦„ ìš”ì•½
        flow_summary = df.groupby(['First_Warehouse', 'Final_Site']).agg({
            'Quantity': 'sum',
            'SQM': 'sum',
            'Lead_Time_Days': 'mean',
            'Case No.': 'count'
        }).reset_index()
        
        flow_summary.rename(columns={
            'Case No.': 'Total_Cases',
            'Lead_Time_Days': 'Avg_Lead_Time_Days'
        }, inplace=True)
        
        # 2. ì›”ë³„ ì²˜ë¦¬ëŸ‰ íŠ¸ë Œë“œ
        monthly_trend = df.groupby(['Month']).agg({
            'Quantity': 'sum',
            'SQM': 'sum',
            'Lead_Time_Days': 'mean',
            'Case No.': 'count'
        }).reset_index()
        
        monthly_trend.rename(columns={
            'Case No.': 'Monthly_Cases',
            'Quantity': 'Monthly_Quantity',
            'SQM': 'Monthly_SQM',
            'Lead_Time_Days': 'Avg_Monthly_Lead_Time'
        }, inplace=True)
        
        # 3. ê³µê¸‰ì‚¬ë³„ ì„±ê³¼
        supplier_performance = df.groupby(['Supplier']).agg({
            'Quantity': 'sum',
            'SQM': 'sum',
            'Lead_Time_Days': ['mean', 'min', 'max', 'std'],
            'Case No.': 'count'
        }).reset_index()
        
        # ë©€í‹°ë ˆë²¨ ì»¬ëŸ¼ í‰ë©´í™”
        supplier_performance.columns = [
            'Supplier', 'Total_Quantity', 'Total_SQM', 
            'Avg_Lead_Time', 'Min_Lead_Time', 'Max_Lead_Time', 'Std_Lead_Time',
            'Total_Cases'
        ]
        
        return flow_summary, monthly_trend, supplier_performance

# --- 4. ENHANCED DATA PROCESSING (í–¥ìƒëœ ë°ì´í„° ì²˜ë¦¬) ---
def deep_match_column(df, target_patterns, fuzzy=True, threshold=0.7):
    """ê°œì„ ëœ ì»¬ëŸ¼ ë§¤ì¹­ í•¨ìˆ˜"""
    df_columns = [str(col).strip() for col in df.columns]
    df_columns_lower = [col.lower() for col in df_columns]
    
    # ì •í™•í•œ ë§¤ì¹­ ìš°ì„ 
    for pattern in target_patterns:
        for i, col_lower in enumerate(df_columns_lower):
            if pattern.lower() in col_lower or col_lower in pattern.lower():
                return df.columns[i]
    
    # í¼ì§€ ë§¤ì¹­
    if fuzzy:
        best_match = None
        best_ratio = 0
        
        for pattern in target_patterns:
            for i, col in enumerate(df_columns):
                ratio = SequenceMatcher(None, pattern.lower(), col.lower()).ratio()
                if ratio > best_ratio and ratio >= threshold:
                    best_ratio = ratio
                    best_match = df.columns[i]
        
        if best_match:
            print(f"   - INFO: Fuzzy matched '{best_match}' to pattern '{target_patterns[0]}' (ratio: {best_ratio:.2f})")
            return best_match
    
    return None

def find_and_get_dimension(df, dim_chars, full_names, fuzzy=True, threshold=0.7):
    """ì¹˜ìˆ˜ ì»¬ëŸ¼ ì°¾ê¸° ë° ë³€í™˜"""
    all_patterns = dim_chars + full_names
    found_col_name = deep_match_column(df, all_patterns, fuzzy=fuzzy, threshold=threshold)
    unit = 'm'  # ê¸°ë³¸ ë‹¨ìœ„
    
    if found_col_name:
        col_str = str(found_col_name).lower()
        if '(cm)' in col_str or 'cm' in col_str:
            unit = 'cm'
        elif '(kg)' in col_str or 'kg' in col_str:
            unit = 'kg'
        elif '(m)' in col_str or 'm' in col_str:
            unit = 'm'
        
        dim_series = pd.to_numeric(df[found_col_name], errors='coerce').fillna(0)
        
        # ë‹¨ìœ„ ë³€í™˜
        if unit == 'cm':
            print(f"   - INFO: Column '{found_col_name}' detected with 'cm' unit. Converting to meters.")
            return dim_series / 100
        elif unit == 'kg':
            print(f"   - INFO: Column '{found_col_name}' detected with 'kg' unit.")
            return dim_series
        else:
            return dim_series
    
    return pd.Series([0] * len(df), index=df.index)

def process_movement_file(excel_path, file_key, warehouse_cols, sheet_name, delivery_tracker, warehouse_analyzer, site_analyzer, integrated_analyzer):
    """ê°œì„ ëœ Movement íŒŒì¼ ì²˜ë¦¬ (ì›”ë³„ ë¶„ì„ í¬í•¨)"""
    try:
        df = pd.read_excel(excel_path, sheet_name=sheet_name)
    except ValueError:
        print(f"   - INFO: Sheet '{sheet_name}' not found. Reading first sheet.")
        df = pd.read_excel(excel_path, sheet_name=0)
    except Exception as e:
        print(f" âš ï¸ File Error: Could not read '{excel_path}'. Reason: {e}")
        return None

    df['Supplier'] = file_key
    
    # í•„ìˆ˜ ì»¬ëŸ¼ ë§¤í•‘
    case_col = deep_match_column(df, ['case', 'carton', 'box', 'mr#', 'sct ship no.', 'case no'])
    if case_col:
        df.rename(columns={case_col: 'Case No.'}, inplace=True)
    else:
        print(f"   - âš ï¸ CRITICAL: 'Case No.' column not found in {excel_path}")
        return None
    
    # Quantity ì²˜ë¦¬
    qty_col = deep_match_column(df, ["q'ty", 'qty', 'quantity', 'qty shipped', 'received'])
    if qty_col:
        df['Quantity'] = pd.to_numeric(df[qty_col], errors='coerce').fillna(1)
    else:
        df['Quantity'] = 1
    
    # ì¹˜ìˆ˜ ê³„ì‚°
    length_m = find_and_get_dimension(df, ['l(m)', 'l(cm)', 'length'], ['length'])
    width_m = find_and_get_dimension(df, ['w(m)', 'w(cm)', 'width'], ['width'])
    height_m = find_and_get_dimension(df, ['h(m)', 'h(cm)', 'height'], ['height'])
    
    if length_m.sum() == 0 or width_m.sum() == 0:
        print(f"   - âš ï¸ WARNING: Could not find valid Length/Width columns in '{excel_path}'.")
    
    df['SQM'] = length_m * width_m
    df['CBM'] = df['SQM'] * height_m
    
    # ë‚ ì§œ ì»¬ëŸ¼ ì²˜ë¦¬
    all_location_cols = warehouse_cols + SITE_COLS
    for col in all_location_cols:
        if col in df.columns:
            df[col] = pd.to_datetime(df[col], errors='coerce')
    
    # ê° ë¶„ì„ê¸°ì— ë°ì´í„° ì¶”ê°€
    for idx, row in df.iterrows():
        case_no = row['Case No.']
        quantity = row['Quantity']
        sqm = row['SQM'] * quantity  # ì´ ë©´ì 
        cbm = row['CBM'] * quantity  # ì´ ë¶€í”¼
        supplier = row['Supplier']
        
        # ì°½ê³  ë‚ ì§œë“¤
        warehouse_dates = {}
        warehouse_sequence = []
        all_dates = []
        
        for warehouse in warehouse_cols:
            if warehouse in df.columns and pd.notna(row[warehouse]):
                warehouse_dates[warehouse] = row[warehouse]
                warehouse_sequence.append(warehouse)
                all_dates.append(row[warehouse])
        
        # í˜„ì¥ ë‚ ì§œë“¤
        site_dates = {}
        final_site = None
        final_delivery_date = None
        
        for site in SITE_COLS:
            if site in df.columns and pd.notna(row[site]):
                site_dates[site] = row[site]
                final_site = site
                final_delivery_date = row[site]
                all_dates.append(row[site])
        
        # 1. ê¸°ì¡´ ë°°ì†¡ ì¶”ì ê¸°ì— ì¶”ê°€
        delivery_tracker.add_case_journey(
            case_no, quantity, sqm, cbm, supplier, warehouse_dates, site_dates
        )
        
        # 2. ì°½ê³ ë³„ ì›”ë³„ ë¶„ì„ê¸°ì— ì¶”ê°€
        warehouse_analyzer.add_warehouse_movement(
            case_no, quantity, sqm, supplier, warehouse_dates
        )
        
        # 3. í˜„ì¥ë³„ ì›”ë³„ ë¶„ì„ê¸°ì— ì¶”ê°€ (ìµœì¢… ë°°ì†¡ì´ ìˆëŠ” ê²½ìš°)
        if final_site and final_delivery_date:
            # ë°°ì†¡ ì§ì „ ì°½ê³  ì°¾ê¸°
            source_warehouse = None
            if warehouse_sequence:
                source_warehouse = warehouse_sequence[-1]  # ë§ˆì§€ë§‰ ì°½ê³ 
            
            site_analyzer.add_site_delivery(
                case_no, quantity, sqm, supplier, source_warehouse, final_site, final_delivery_date
            )
        
        # 4. í†µí•© ë¶„ì„ê¸°ì— ì¶”ê°€
        if warehouse_sequence and final_site and all_dates:
            integrated_analyzer.add_flow_record(
                case_no, quantity, sqm, supplier, warehouse_sequence, final_site, all_dates
            )
    
    return df

def format_excel_sheet(df, writer, sheet_name):
    """ì—‘ì…€ ì‹œíŠ¸ ì„œì‹ ì§€ì •"""
    df.to_excel(writer, sheet_name=sheet_name, index=False)
    workbook = writer.book
    worksheet = writer.sheets[sheet_name]
    
    # í—¤ë” ì„œì‹
    header_format = workbook.add_format({
        'bold': True, 'text_wrap': True, 'valign': 'top', 
        'fg_color': '#D7E4BC', 'border': 1, 'align': 'center'
    })
    
    # ìˆ«ì ì„œì‹
    number_format = workbook.add_format({'num_format': '#,##0.00'})
    
    for col_num, value in enumerate(df.columns.values):
        worksheet.write(0, col_num, value, header_format)
    
    # ìˆ«ì ì»¬ëŸ¼ì— ì„œì‹ ì ìš©
    for i, col in enumerate(df.columns):
        if col in ['Box Qty', 'SQM', 'CBM', 'Quantity', 'Monthly_Inbound', 'Monthly_SQM_Inbound', 
                   'Monthly_Delivery', 'Monthly_SQM_Delivery', 'Total_Quantity', 'Total_SQM']:
            worksheet.set_column(i, i, 15, number_format)
        else:
            col_width = max(df[col].astype(str).map(len).max(), len(str(col))) + 2
            worksheet.set_column(i, i, min(col_width, 30))

def check_and_copy_files():
    """íŒŒì¼ ì¡´ì¬ í™•ì¸ ë° ë³µì‚¬ ê°€ì´ë“œ"""
    print("ğŸ“ Checking file availability...")
    
    # ì›ë³¸ íŒŒì¼ ìœ„ì¹˜
    source_files = {
        'HITACHI': r'C:\Users\SAMSUNG\Desktop\HVDC WAREHOUSE_HITACHI(HE).xlsx',
        'HITACHI_LOCAL': r'C:\Users\SAMSUNG\Desktop\ì •ë¦¬ëœ_íŒŒì¼\05_ì°½ê³ _ìŠ¤í† ë¦¬ì§€\HVDC WAREHOUSE_HITACHI(HE_LOCAL).xlsx',
        'HITACHI_LOT': r'C:\Users\SAMSUNG\Desktop\HE_í”„ë¡œì íŠ¸\HVDC WAREHOUSE_HITACHI(HE-0214,0252).xlsx',
        'SIEMENS': r'C:\Users\SAMSUNG\Desktop\ì •ë¦¬ëœ_íŒŒì¼\05_ì°½ê³ _ìŠ¤í† ë¦¬ì§€\HVDC WAREHOUSE_SIMENSE(SIM).xlsx',
    }
    
    missing_files = []
    available_files = []
    
    for key, target_path in FILE_MAP.items():
        if os.path.exists(target_path):
            available_files.append(f"   âœ… {key}: {target_path}")
        else:
            source_path = source_files[key]
            if os.path.exists(source_path):
                try:
                    import shutil
                    os.makedirs(os.path.dirname(target_path), exist_ok=True)
                    shutil.copy2(source_path, target_path)
                    print(f"   ğŸ“‹ Auto-copied: {key}")
                    available_files.append(f"   âœ… {key}: {target_path} (auto-copied)")
                except Exception as e:
                    print(f"   âŒ Failed to copy {key}: {e}")
                    missing_files.append(key)
            else:
                print(f"   âŒ Source not found: {key} at {source_path}")
                missing_files.append(key)
    
    if available_files:
        print("Available files:")
        for file_info in available_files:
            print(file_info)
    
    if missing_files:
        print(f"\nâš ï¸  Missing files: {missing_files}")
        print("Please manually copy the files to the data folder:")
        for key in missing_files:
            print(f"   Copy: {source_files[key]}")
            print(f"   To: {FILE_MAP[key]}")
        return False
    
    return True

def create_monthly_analysis_sheets(warehouse_analyzer, site_analyzer, integrated_analyzer, writer):
    """ì›”ë³„ ë¶„ì„ ì‹œíŠ¸ë“¤ ìƒì„±"""
    
    print("   ğŸ“Š Creating monthly analysis sheets...")
    
    # 1. ì°½ê³ ë³„ ì›”ë³„ ë¶„ì„
    warehouse_summary, warehouse_pivot = warehouse_analyzer.get_monthly_warehouse_summary()
    if not warehouse_summary.empty:
        # ê¸°ë³¸ ìš”ì•½
        format_excel_sheet(warehouse_summary, writer, 'Monthly_Warehouse_Summary')
        print("   âœ… 'Monthly_Warehouse_Summary' sheet created.")
        
        # í”¼ë²— í…Œì´ë¸” (ì›”ë³„ íŠ¸ë Œë“œ) - MultiIndex ì˜¤ë¥˜ ë°©ì§€
        if not warehouse_pivot.empty:
            try:
                format_excel_sheet(warehouse_pivot, writer, 'Warehouse_Monthly_Trend')
                print("   âœ… 'Warehouse_Monthly_Trend' sheet created.")
            except Exception as e:
                print(f"   âš ï¸ Could not create 'Warehouse_Monthly_Trend' sheet: {e}")
    
    # 2. í˜„ì¥ë³„ ì›”ë³„ ë¶„ì„
    site_summary, site_pivot = site_analyzer.get_monthly_site_summary()
    if not site_summary.empty:
        # ê¸°ë³¸ ìš”ì•½
        format_excel_sheet(site_summary, writer, 'Monthly_Site_Summary')
        print("   âœ… 'Monthly_Site_Summary' sheet created.")
        
        # í”¼ë²— í…Œì´ë¸” (ì›”ë³„ íŠ¸ë Œë“œ) - MultiIndex ì˜¤ë¥˜ ë°©ì§€
        if not site_pivot.empty:
            try:
                format_excel_sheet(site_pivot, writer, 'Site_Monthly_Trend')
                print("   âœ… 'Site_Monthly_Trend' sheet created.")
            except Exception as e:
                print(f"   âš ï¸ Could not create 'Site_Monthly_Trend' sheet: {e}")
    
    # 3. í†µí•© ë¶„ì„
    flow_summary, monthly_trend, supplier_performance = integrated_analyzer.get_integrated_analysis()
    
    if not flow_summary.empty:
        format_excel_sheet(flow_summary, writer, 'Integrated_Flow_Analysis')
        print("   âœ… 'Integrated_Flow_Analysis' sheet created.")
    
    if not monthly_trend.empty:
        format_excel_sheet(monthly_trend, writer, 'Monthly_Trend_Overall')
        print("   âœ… 'Monthly_Trend_Overall' sheet created.")
    
    if not supplier_performance.empty:
        format_excel_sheet(supplier_performance, writer, 'Supplier_Performance')
        print("   âœ… 'Supplier_Performance' sheet created.")

def create_comprehensive_dashboard(warehouse_analyzer, site_analyzer, integrated_analyzer, delivery_tracker):
    """ì¢…í•© ëŒ€ì‹œë³´ë“œ ë°ì´í„° ìƒì„±"""
    
    # ê¸°ë³¸ í†µê³„
    total_cases = len(delivery_tracker.deliveries)
    
    # ì°½ê³ ë³„ í†µê³„
    warehouse_summary, _ = warehouse_analyzer.get_monthly_warehouse_summary()
    warehouse_stats = {}
    if not warehouse_summary.empty:
        warehouse_stats = warehouse_summary.groupby('Warehouse').agg({
            'Monthly_Inbound': 'sum',
            'Monthly_SQM_Inbound': 'sum',
            'Cases_Count': 'sum'
        }).to_dict()
    
    # í˜„ì¥ë³„ í†µê³„
    site_summary, _ = site_analyzer.get_monthly_site_summary()
    site_stats = {}
    if not site_summary.empty:
        site_stats = site_summary.groupby('Site').agg({
            'Monthly_Delivery': 'sum',
            'Monthly_SQM_Delivery': 'sum',
            'Cases_Count': 'sum'
        }).to_dict()
    
    # í†µí•© ë¶„ì„ í†µê³„
    flow_summary, monthly_trend, supplier_performance = integrated_analyzer.get_integrated_analysis()
    
    dashboard_data = {
        'Analysis_Date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'Total_Cases_Processed': total_cases,
        'Unique_Warehouses': len(warehouse_stats) if warehouse_stats else 0,
        'Unique_Sites': len(site_stats) if site_stats else 0,
        'Analysis_Period': f"{monthly_trend['Month'].min()} to {monthly_trend['Month'].max()}" if not monthly_trend.empty else 'N/A',
        'Avg_Lead_Time_Days': monthly_trend['Avg_Monthly_Lead_Time'].mean() if not monthly_trend.empty else 0,
        'Total_Monthly_Quantity': monthly_trend['Monthly_Quantity'].sum() if not monthly_trend.empty else 0,
        'Total_Monthly_SQM': monthly_trend['Monthly_SQM'].sum() if not monthly_trend.empty else 0
    }
    
    return pd.DataFrame([dashboard_data])

def main():
    """ë©”ì¸ ë¶„ì„ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ Starting HVDC Comprehensive Warehouse Analysis...")
    print("ğŸ“‹ Target: ì°½ê³ ë³„/í˜„ì¥ë³„ ì›”ë³„ ë¶„ì„ + í†µí•© ëŒ€ì‹œë³´ë“œ")
    
    # íŒŒì¼ ì¡´ì¬ í™•ì¸ ë° ìë™ ë³µì‚¬ ì‹œë„
    if not check_and_copy_files():
        print("\nâŒ Required files are missing. Please copy files manually and try again.")
        return
    
    # ëª¨ë“  ë¶„ì„ê¸° ì´ˆê¸°í™”
    delivery_tracker = WarehouseToSiteTracker()
    warehouse_analyzer = MonthlyWarehouseAnalyzer()
    site_analyzer = MonthlySiteAnalyzer()
    integrated_analyzer = IntegratedAnalyzer()
    all_raw_data = []
    
    # Movement íŒŒì¼ë“¤ ì²˜ë¦¬
    for supplier, path in FILE_MAP.items():
        print(f"   - Processing: {supplier} ({path})")
        sheet_name = SHEET_NAME_MAP.get(supplier, 'CASE LIST')
        raw_df = process_movement_file(
            path, supplier, WAREHOUSE_COLS_MAP[supplier], sheet_name, 
            delivery_tracker, warehouse_analyzer, site_analyzer, integrated_analyzer
        )
        if raw_df is not None:
            all_raw_data.append(raw_df)
    
    if not all_raw_data:
        print("âš ï¸ No movement data processed. Aborting.")
        return
    
    print(f"\nğŸ“Š Processing {len(delivery_tracker.deliveries)} delivery records...")
    
    # ê¸°ì¡´ ì°½ê³ â†’í˜„ì¥ ë°°ì†¡ ìš”ì•½ ìƒì„±
    warehouse_to_site_df = delivery_tracker.get_warehouse_to_site_summary()
    
    if warehouse_to_site_df.empty:
        print("âš ï¸ No warehouse-to-site deliveries found.")
        return
    
    print("   - Warehouse-to-Site delivery summary generated.")
    
    # ê¸°ì¡´ ì¶œë ¥ (ì½˜ì†”)
    print("\nğŸ“‹ WAREHOUSE-TO-SITE DELIVERY SUMMARY:")
    print("=" * 50)
    
    for location in warehouse_to_site_df['Location'].unique():
        location_data = warehouse_to_site_df[warehouse_to_site_df['Location'] == location]
        print(f"\n{location}:")
        
        total_qty = 0
        total_sqm = 0
        
        for _, row in location_data.iterrows():
            print(f"  {row['Site']}: {row['Box Qty']:,} boxes, {row['SQM']:,.2f} SQM")
            total_qty += row['Box Qty']
            total_sqm += row['SQM']
        
        print(f"  Subtotal: {total_qty:,} boxes, {total_sqm:,.2f} SQM")
    
    grand_total_qty = warehouse_to_site_df['Box Qty'].sum()
    grand_total_sqm = warehouse_to_site_df['SQM'].sum()
    print(f"\nGrand Total: {grand_total_qty:,} boxes, {grand_total_sqm:,.2f} SQM")
    
    # ì¢…í•© ëŒ€ì‹œë³´ë“œ ìƒì„±
    dashboard_df = create_comprehensive_dashboard(
        warehouse_analyzer, site_analyzer, integrated_analyzer, delivery_tracker
    )
    
    # ì—‘ì…€ íŒŒì¼ ì¶œë ¥ (í™•ì¥ëœ ë²„ì „)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_filename = f"HVDC_Comprehensive_Analysis_{timestamp}.xlsx"
    output_path = os.path.join(outputs_dir, output_filename)
    
    with pd.ExcelWriter(output_path, engine='xlsxwriter') as writer:
        # ğŸ“Š ëŒ€ì‹œë³´ë“œ ì‹œíŠ¸
        if not dashboard_df.empty:
            format_excel_sheet(dashboard_df, writer, 'Dashboard')
            print("   âœ… 'Dashboard' sheet created.")
        
        # ğŸ“‹ ê¸°ì¡´ ì‹œíŠ¸ë“¤
        format_excel_sheet(warehouse_to_site_df, writer, 'Warehouse_to_Site_Summary')
        print("   âœ… 'Warehouse_to_Site_Summary' sheet created.")
        
        if delivery_tracker.deliveries:
            detailed_df = pd.DataFrame(delivery_tracker.deliveries)
            format_excel_sheet(detailed_df, writer, 'Detailed_Delivery_Records')
            print("   âœ… 'Detailed_Delivery_Records' sheet created.")
        
        # ğŸ¯ ìƒˆë¡œìš´ ì›”ë³„ ë¶„ì„ ì‹œíŠ¸ë“¤
        create_monthly_analysis_sheets(warehouse_analyzer, site_analyzer, integrated_analyzer, writer)
        
        # ğŸ“Š ì›ë³¸ ë°ì´í„° (ì°¸ê³ ìš©)
        if all_raw_data:
            master_df = pd.concat(all_raw_data, ignore_index=True, sort=False)
            format_excel_sheet(master_df, writer, 'Raw_Movement_Data')
            print("   âœ… 'Raw_Movement_Data' sheet created.")
    
    print(f"\nğŸ“¦ Comprehensive Report saved to: '{output_path}'")
    
    # ğŸ“Š ì›”ë³„ ë¶„ì„ ìš”ì•½ ì¶œë ¥
    print("\nğŸ“Š MONTHLY ANALYSIS SUMMARY:")
    print("=" * 50)
    
    # ì°½ê³ ë³„ ì›”ë³„ ìš”ì•½
    warehouse_summary, _ = warehouse_analyzer.get_monthly_warehouse_summary()
    if not warehouse_summary.empty:
        print("\nğŸ¢ ì°½ê³ ë³„ ì›”ë³„ ì…ê³  í˜„í™©:")
        warehouse_monthly = warehouse_summary.groupby('Warehouse').agg({
            'Monthly_Inbound': 'sum',
            'Monthly_SQM_Inbound': 'sum',
            'Cases_Count': 'sum'
        })
        for warehouse in warehouse_monthly.index:
            data = warehouse_monthly.loc[warehouse]
            print(f"  {warehouse}: {data['Monthly_Inbound']:,} boxes, {data['Monthly_SQM_Inbound']:,.2f} SQM, {data['Cases_Count']:,} cases")
    
    # í˜„ì¥ë³„ ì›”ë³„ ìš”ì•½
    site_summary, _ = site_analyzer.get_monthly_site_summary()
    if not site_summary.empty:
        print("\nğŸ—ï¸ í˜„ì¥ë³„ ì›”ë³„ ë°°ì†¡ í˜„í™©:")
        site_monthly = site_summary.groupby('Site').agg({
            'Monthly_Delivery': 'sum',
            'Monthly_SQM_Delivery': 'sum',
            'Cases_Count': 'sum'
        })
        for site in site_monthly.index:
            data = site_monthly.loc[site]
            print(f"  {site}: {data['Monthly_Delivery']:,} boxes, {data['Monthly_SQM_Delivery']:,.2f} SQM, {data['Cases_Count']:,} cases")
    
    # í†µí•© ë¶„ì„ ìš”ì•½
    flow_summary, monthly_trend, supplier_performance = integrated_analyzer.get_integrated_analysis()
    if not monthly_trend.empty:
        print("\nğŸ“ˆ ì›”ë³„ ì „ì²´ ì²˜ë¦¬ëŸ‰ íŠ¸ë Œë“œ:")
        for _, row in monthly_trend.iterrows():
            print(f"  {row['Month']}: {row['Monthly_Quantity']:,} boxes, {row['Monthly_SQM']:,.2f} SQM, í‰ê·  ë¦¬ë“œíƒ€ì„ {row['Avg_Monthly_Lead_Time']:.1f}ì¼")
    
    if not supplier_performance.empty:
        print("\nğŸ­ ê³µê¸‰ì‚¬ë³„ ì„±ê³¼:")
        for _, row in supplier_performance.iterrows():
            print(f"  {row['Supplier']}: {row['Total_Quantity']:,} boxes, í‰ê·  ë¦¬ë“œíƒ€ì„ {row['Avg_Lead_Time']:.1f}ì¼")
    
    print("\nğŸ¯ Expected vs Actual Comparison:")
    print("   - DSV AL MARKAZ ì˜ˆìƒ: 812 boxes, 4,856.87 SQM")
    print("   - DSV Indoor ì˜ˆìƒ: 414 boxes, 2,458.27 SQM")
    print("   - Grand Total ì˜ˆìƒ: 1,226 boxes, 7,315.14 SQM")
    print("\nğŸ“‹ Generated Analysis Sheets:")
    print("   1. Dashboard - ì¢…í•© ê°œìš”")
    print("   2. Warehouse_to_Site_Summary - ì°½ê³ â†’í˜„ì¥ ë°°ì†¡ ìš”ì•½")
    print("   3. Monthly_Warehouse_Summary - ì°½ê³ ë³„ ì›”ë³„ ì…ê³ /ì¬ê³ ")
    print("   4. Monthly_Site_Summary - í˜„ì¥ë³„ ì›”ë³„ ì…ê³ /ì¬ê³ ")
    print("   5. Integrated_Flow_Analysis - í†µí•© íë¦„ ë¶„ì„")
    print("   6. Monthly_Trend_Overall - ì „ì²´ ì›”ë³„ íŠ¸ë Œë“œ")
    print("   7. Supplier_Performance - ê³µê¸‰ì‚¬ë³„ ì„±ê³¼")
    print("   8. Detailed_Delivery_Records - ìƒì„¸ ë°°ì†¡ ê¸°ë¡")
    print("   9. Raw_Movement_Data - ì›ë³¸ ë°ì´í„°")
    
    try:
        if os.name == 'nt': 
            subprocess.run(['start', output_path], shell=True, check=True)
        else: 
            os.system(f"open '{output_path}'")
    except Exception as e:
        print(f"âš ï¸ Could not open file automatically: {e}")


if __name__ == '__main__':
    main()